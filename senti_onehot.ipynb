{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Before this line are method predefined</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):  \n",
    "    \"\"\" \n",
    "    Tokenization/string cleaning for dataset \n",
    "    Every dataset is lower cased except \n",
    "    \"\"\"  \n",
    "    sens = word_tokenize(string.lower())\n",
    "    sens = [word for word in sens if not word in english_stopwords]\n",
    "    sens = [word for word in sens if not word in english_punctuations]\n",
    "    sens = [lemmatizer.lemmatize(word) for word in sens]\n",
    "    sens = [word for word in sens if word.isalpha()]\n",
    "    sens = ' '.join(sens)\n",
    "    return sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_2d(X, label):\n",
    "    # only for this case!\n",
    "    plt.figure()\n",
    "    # plt.scatter(aa[:,0],aa[:,1])\n",
    "    point_1 = []\n",
    "    point_0 = []\n",
    "    point_2 = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i]== '1' or label[i]== 1:\n",
    "            point_1.append(X[i])\n",
    "        elif label[i]== '0' or label[i]== 0:\n",
    "            point_0.append(X[i])\n",
    "        else:\n",
    "            point_2.append(X[i])\n",
    "    point_1 = np.asarray(point_1)\n",
    "    point_0 = np.asarray(point_0)\n",
    "    point_2 = np.asarray(point_2)\n",
    "    plt.scatter(point_1[:,0],point_1[:,1],color='red')\n",
    "    plt.scatter(point_0[:,0],point_0[:,1],color='g')\n",
    "    plt.scatter(point_2[:,0],point_2[:,1],color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_tsne(X, label):\n",
    "    ts = TSNE()\n",
    "    X_lower = ts.fit_transform(X.reshape(X.shape[0], X.shape[2]),)\n",
    "    plot_2d(X_lower, label)\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Now we do some preprocessing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.02\n",
    "MAX_FEATURES = 2000\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "DECAY = 2e-4  # about half each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['airline_sentiment']\n",
    "y.replace({'neutral':'2', 'positive':'1', 'negative':'0'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9178\n",
       "2    3099\n",
       "1    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocssing, stopwords and rare words, tokenization and vectorizing\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "english_stopwords = stopwords.words('english')\n",
    "english_punctuations = [',', '.','\\'s', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']\n",
    "X = X.apply(clean_str)\n",
    "\n",
    "# vectorizing using tfidf\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2), max_df = 0.95,min_df = 0.001, max_features = MAX_FEATURES)\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:red\"> For our first model, bidirectional LSTM with fine-tuning </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11712, 1, 1618)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 517)\n",
    "X_train = X_train.toarray()\n",
    "X_train = np.reshape(X_train,(X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.toarray()\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=3)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dense_76_input (InputLayer)     (None, 1, 1618)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 1618)      0           dense_76_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 1618)      0           dense_76_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_35 (Sequential)      (None, 3)            1132803     lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Concatenate)          (None, 3)            0           sequential_35[1][0]              \n",
      "                                                                 sequential_35[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,132,803\n",
      "Trainable params: 1,132,803\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bi_lstm = Sequential()\n",
    "bi_lstm.add(Dense(512, activation = 'relu', input_shape = (1, X_train.shape[2])))\n",
    "bi_lstm.add(Dropout(0.3))\n",
    "bi_lstm.add(Bidirectional(LSTM(64 ,dropout = 0.7,recurrent_dropout = 0.3, return_sequences=False)))\n",
    "bi_lstm.add(Dense(64, activation = 'relu'))\n",
    "bi_lstm.add(Dense(3,activation = 'softmax'))\n",
    "bi_lstm = multi_gpu_model(bi_lstm)\n",
    "bi_lstm.summary()\n",
    "\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9369 samples, validate on 2343 samples\n",
      "Epoch 1/100\n",
      " - 31s - loss: 0.8973 - acc: 0.6306 - val_loss: 0.8731 - val_acc: 0.6116\n",
      "Epoch 2/100\n",
      " - 19s - loss: 0.7968 - acc: 0.6454 - val_loss: 0.7547 - val_acc: 0.6765\n",
      "Epoch 3/100\n",
      " - 18s - loss: 0.6971 - acc: 0.7099 - val_loss: 0.7042 - val_acc: 0.6948\n",
      "Epoch 4/100\n",
      " - 19s - loss: 0.6345 - acc: 0.7416 - val_loss: 0.6350 - val_acc: 0.7311\n",
      "Epoch 5/100\n",
      " - 18s - loss: 0.5824 - acc: 0.7597 - val_loss: 0.6160 - val_acc: 0.7473\n",
      "Epoch 6/100\n",
      " - 19s - loss: 0.5443 - acc: 0.7818 - val_loss: 0.6137 - val_acc: 0.7520\n",
      "Epoch 7/100\n",
      " - 19s - loss: 0.5069 - acc: 0.7986 - val_loss: 0.5856 - val_acc: 0.7670\n",
      "Epoch 8/100\n",
      " - 19s - loss: 0.4739 - acc: 0.8099 - val_loss: 0.5777 - val_acc: 0.7665\n",
      "Epoch 9/100\n",
      " - 20s - loss: 0.4480 - acc: 0.8236 - val_loss: 0.5885 - val_acc: 0.7648\n",
      "Epoch 10/100\n",
      " - 20s - loss: 0.4192 - acc: 0.8325 - val_loss: 0.6018 - val_acc: 0.7725\n",
      "Epoch 11/100\n",
      " - 20s - loss: 0.3919 - acc: 0.8433 - val_loss: 0.6159 - val_acc: 0.7704\n",
      "Epoch 12/100\n",
      " - 20s - loss: 0.3686 - acc: 0.8539 - val_loss: 0.6236 - val_acc: 0.7700\n",
      "Epoch 13/100\n",
      " - 20s - loss: 0.3388 - acc: 0.8665 - val_loss: 0.6289 - val_acc: 0.7687\n",
      "Epoch 14/100\n",
      " - 20s - loss: 0.3266 - acc: 0.8737 - val_loss: 0.6229 - val_acc: 0.7695\n",
      "Epoch 15/100\n",
      " - 20s - loss: 0.2971 - acc: 0.8816 - val_loss: 0.7163 - val_acc: 0.7640\n",
      "Epoch 16/100\n",
      " - 20s - loss: 0.2858 - acc: 0.8906 - val_loss: 0.6665 - val_acc: 0.7674\n",
      "Epoch 17/100\n",
      " - 20s - loss: 0.2645 - acc: 0.8992 - val_loss: 0.7089 - val_acc: 0.7657\n",
      "Epoch 18/100\n",
      " - 20s - loss: 0.2511 - acc: 0.9016 - val_loss: 0.7581 - val_acc: 0.7392\n",
      "Epoch 19/100\n",
      " - 20s - loss: 0.2382 - acc: 0.9091 - val_loss: 0.7376 - val_acc: 0.7691\n",
      "Epoch 20/100\n",
      " - 20s - loss: 0.2164 - acc: 0.9151 - val_loss: 0.7616 - val_acc: 0.7678\n",
      "Epoch 21/100\n",
      " - 21s - loss: 0.2010 - acc: 0.9258 - val_loss: 0.7836 - val_acc: 0.7653\n",
      "Epoch 22/100\n",
      " - 20s - loss: 0.2002 - acc: 0.9221 - val_loss: 0.7949 - val_acc: 0.7721\n",
      "Epoch 23/100\n",
      " - 20s - loss: 0.1859 - acc: 0.9274 - val_loss: 0.8759 - val_acc: 0.7678\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb83952f28>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lstm.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr = LEARNING_RATE), metrics=['accuracy'])\n",
    "bi_lstm.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks = [earlystopping], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2928/2928 [==============================] - 1s 179us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8927651204046656, 0.7715163934426229]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lstm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:red\">SVM with Tf-Idf!</span>\n",
    "###  Use train and test from above. We are doing based on One-hot embedding method. We will try to do GloVe later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use train and test from above. We are doing based on TFIDF embedding method. We will try to do GloVe later.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 517)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100], 'gamma': [0.1, 1, 10], 'kernel': ('linear', 'rbf')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, grid_search\n",
    "\n",
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10,100], 'gamma':[0.1,1,10]}\n",
    "# svr = svm.SVC(class_weight = 'balanced', verbose = True)\n",
    "# clf = grid_search.GridSearchCV(svr, parameters)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764344262295082"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'rbf',gamma = 0.1, C = 10,class_weight = 'balanced', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
